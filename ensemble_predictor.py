"""
Ensemble Methods for Combined Predictions
YOLO Mode Implementation - Advanced Ensemble Learning Pipeline

Combines multiple ML models using cutting-edge ensemble techniques:
- Stacking ensemble with meta-learner
- Bayesian model averaging
- Dynamic weighting based on confidence
- Diversity-based ensemble selection
- Online learning adaptation
- Gradient Boosting (XGBoost + LightGBM) ensemble
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Tuple, Callable
import logging
from datetime import datetime
from pathlib import Path
from sklearn.model_selection import cross_val_predict, KFold
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.metrics import accuracy_score, mean_absolute_error, log_loss
from sklearn.preprocessing import StandardScaler
from sklearn.calibration import CalibratedClassifierCV
import warnings
warnings.filterwarnings("ignore")

logger = logging.getLogger(__name__)

class EnsemblePredictor:
    """
    Advanced ensemble prediction system combining multiple models.
    YOLO Mode: Cutting-edge ensemble learning with meta-learning.
    """
    
    def __init__(self, base_models: Optional[List] = None, meta_model=None):
        self.base_models = base_models or []
        self.meta_model = meta_model or LogisticRegression(random_state=42)
        self.model_weights = {}
        self.feature_importance = {}
        self.performance_history = []
        self.ensemble_type = "stacking"  # stacking, blending, or bayesian
        
    def add_base_model(self, model: Any, name: str, model_type: str = "classification"):
        """
        Add a base model to the ensemble.
        
        Args:
            model: Trained model object
            name: Unique name for the model
            model_type: "classification" or "regression"
        """
        self.base_models.append({
            "model": model,
            "name": name,
            "type": model_type,
            "performance": {},
            "weight": 1.0
        })
        logger.info(f"Added base model: {name} ({model_type})")
    
    def generate_meta_features(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> pd.DataFrame:
        """
        Generate meta-features from base models using cross-validation.
        
        Args:
            X: Feature matrix
            y: Target variable (for classification)
            
        Returns:
            DataFrame with meta-features (base model predictions)
        """
        logger.info("Generating meta-features from base models")
        
        meta_features = pd.DataFrame(index=X.index)
        
        for base_model_info in self.base_models:
            model = base_model_info["model"]
            name = base_model_info["name"]
            model_type = base_model_info["type"]
            
            try:
                if y is not None and len(self.base_models) > 1:
                    # Use cross-validation to prevent overfitting
                    if model_type == "classification":
                        predictions = cross_val_predict(
                            model, X, y, cv=5, method="predict_proba"
                        )
                        # Use probability of positive class
                        meta_features[f"{name}_proba"] = predictions[:, 1]
                        # Also include hard predictions
                        meta_features[f"{name}_pred"] = cross_val_predict(
                            model, X, y, cv=5, method="predict"
                        )
                    else:  # regression
                        predictions = cross_val_predict(model, X, y, cv=5)
                        meta_features[f"{name}_pred"] = predictions
                else:
                    # Direct prediction (for inference or single model)
                    if model_type == "classification" and hasattr(model, "predict_proba"):
                        predictions = model.predict_proba(X)
                        meta_features[f"{name}_proba"] = predictions[:, 1]
                        meta_features[f"{name}_pred"] = model.predict(X)
                    else:
                        meta_features[f"{name}_pred"] = model.predict(X)
                        
            except Exception as e:
                logger.warning(f"Error generating meta-features for {name}: {e}")
                # Fill with zeros or mean as fallback
                meta_features[f"{name}_pred"] = 0.5 if model_type == "classification" else X.mean().mean()
                if model_type == "classification":
                    meta_features[f"{name}_proba"] = 0.5
        
        # Add ensemble statistics
        pred_cols = [col for col in meta_features.columns if col.endswith("_pred")]
        proba_cols = [col for col in meta_features.columns if col.endswith("_proba")]
        
        if pred_cols:
            meta_features["ensemble_mean_pred"] = meta_features[pred_cols].mean(axis=1)
            meta_features["ensemble_std_pred"] = meta_features[pred_cols].std(axis=1)
            meta_features["ensemble_confidence"] = 1 / (1 + meta_features["ensemble_std_pred"])
        
        if proba_cols:
            meta_features["ensemble_mean_proba"] = meta_features[proba_cols].mean(axis=1)
            meta_features["ensemble_std_proba"] = meta_features[proba_cols].std(axis=1)
        
        logger.info(f"Generated {len(meta_features.columns)} meta-features")
        return meta_features
    
    def train_ensemble(self, X: pd.DataFrame, y: pd.Series, ensemble_type: str = "stacking"):
        """
        Train the ensemble using specified method.
        
        Args:
            X: Feature matrix
            y: Target variable
            ensemble_type: "stacking", "blending", or "bayesian"
        """
        logger.info(f"Training ensemble using {ensemble_type} method")
        self.ensemble_type = ensemble_type
        
        if len(self.base_models) == 0:
            raise ValueError("No base models added to ensemble")
        
        # Generate meta-features
        meta_features = self.generate_meta_features(X, y)
        
        if ensemble_type == "stacking":
            self._train_stacking(meta_features, y)
        elif ensemble_type == "blending":
            self._train_blending(meta_features, y)
        elif ensemble_type == "bayesian":
            self._train_bayesian(meta_features, y)
        else:
            raise ValueError(f"Unknown ensemble type: {ensemble_type}")
        
        logger.info("Ensemble training completed")
    
    def _train_stacking(self, meta_features: pd.DataFrame, y: pd.Series):
        """Train stacking ensemble with meta-learner"""
        logger.info("Training stacking ensemble")
        
        # Scale meta-features
        scaler = StandardScaler()
        meta_features_scaled = pd.DataFrame(
            scaler.fit_transform(meta_features),
            columns=meta_features.columns,
            index=meta_features.index
        )
        
        # Train meta-model
        self.meta_model.fit(meta_features_scaled, y)
        
        # Calculate feature importance for meta-model
        if hasattr(self.meta_model, "coef_"):
            self.feature_importance["meta_model"] = dict(zip(
                meta_features.columns,
                np.abs(self.meta_model.coef_[0]) if len(self.meta_model.coef_.shape) > 1 
                else np.abs(self.meta_model.coef_)
            ))
        
        # Store scaler for later use
        self.meta_scaler = scaler
    
    def _train_blending(self, meta_features: pd.DataFrame, y: pd.Series):
        """Train blending ensemble using weighted averaging"""
        logger.info("Training blending ensemble")
        
        # Simple weighted average based on individual model performance
        weights = {}
        total_weight = 0
        
        for base_model_info in self.base_models:
            name = base_model_info["name"]
            pred_col = f"{name}_pred"
            
            if pred_col in meta_features.columns:
                predictions = meta_features[pred_col]
                # Use correlation with target as weight (higher is better)
                weight = abs(np.corrcoef(predictions, y)[0, 1]) if len(predictions) > 1 else 0.5
                weights[name] = max(weight, 0.1)  # Minimum weight
                total_weight += weights[name]
        
        # Normalize weights
        for name in weights:
            weights[name] /= total_weight
        
        self.model_weights = weights
        logger.info(f"Blending weights: {weights}")
    
    def _train_bayesian(self, meta_features: pd.DataFrame, y: pd.Series):
        """Train Bayesian model averaging ensemble"""
        logger.info("Training Bayesian ensemble")
        
        # Simplified Bayesian model averaging
        # In practice, this would use proper Bayesian inference
        weights = {}
        
        for base_model_info in self.base_models:
            name = base_model_info["name"]
            pred_col = f"{name}_pred"
            
            if pred_col in meta_features.columns:
                predictions = meta_features[pred_col]
                # Use Brier score or similar for weighting
                if len(np.unique(y)) == 2:  # Binary classification
                    brier_score = np.mean((predictions - y) ** 2)
                    weight = 1 / (1 + brier_score)  # Lower Brier score = higher weight
                else:
                    mse = np.mean((predictions - y) ** 2)
                    weight = 1 / (1 + mse)
                
                weights[name] = weight
        
        # Normalize weights
        total_weight = sum(weights.values())
        self.model_weights = {name: weight/total_weight for name, weight in weights.items()}
        
        logger.info(f"Bayesian weights: {self.model_weights}")
    
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """
        Make ensemble predictions.
        
        Args:
            X: Feature matrix
            
        Returns:
            Array of predictions
        """
        if len(self.base_models) == 0:
            raise ValueError("No base models available for prediction")
        
        # Generate meta-features
        meta_features = self.generate_meta_features(X)
        
        if self.ensemble_type == "stacking":
            return self._predict_stacking(meta_features)
        elif self.ensemble_type == "blending":
            return self._predict_blending(meta_features)
        elif self.ensemble_type == "bayesian":
            return self._predict_bayesian(meta_features)
        else:
            # Simple averaging as fallback
            return self._predict_average(meta_features)
    
    def _predict_stacking(self, meta_features: pd.DataFrame) -> np.ndarray:
        """Make predictions using stacking ensemble"""
        meta_features_scaled = self.meta_scaler.transform(meta_features)
        return self.meta_model.predict(meta_features_scaled)
    
    def _predict_blending(self, meta_features: pd.DataFrame) -> np.ndarray:
        """Make predictions using blending ensemble"""
        ensemble_pred = np.zeros(len(meta_features))
        
        for base_model_info in self.base_models:
            name = base_model_info["name"]
            weight = self.model_weights.get(name, 1.0 / len(self.base_models))
            pred_col = f"{name}_pred"
            
            if pred_col in meta_features.columns:
                ensemble_pred += weight * meta_features[pred_col].values
        
        return ensemble_pred
    
    def _predict_bayesian(self, meta_features: pd.DataFrame) -> np.ndarray:
        """Make predictions using Bayesian ensemble"""
        return self._predict_blending(meta_features)  # Same as blending for simplicity
    
    def _predict_average(self, meta_features: pd.DataFrame) -> np.ndarray:
        """Simple averaging of base model predictions"""
        pred_cols = [col for col in meta_features.columns if col.endswith("_pred")]
        if pred_cols:
            return meta_features[pred_cols].mean(axis=1).values
        else:
            return np.full(len(meta_features), 0.5)
    
    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:
        """
        Make probability predictions for classification.
        
        Args:
            X: Feature matrix
            
        Returns:
            Array of prediction probabilities
        """
        meta_features = self.generate_meta_features(X)
        
        if self.ensemble_type == "stacking" and hasattr(self.meta_model, "predict_proba"):
            meta_features_scaled = self.meta_scaler.transform(meta_features)
            return self.meta_model.predict_proba(meta_features_scaled)[:, 1]
        else:
            # Use probability averaging
            proba_cols = [col for col in meta_features.columns if col.endswith("_proba")]
            if proba_cols:
                return meta_features[proba_cols].mean(axis=1).values
            else:
                # Fallback to prediction-based probabilities
                preds = self.predict(X)
                return preds
    
    def get_ensemble_confidence(self, X: pd.DataFrame) -> np.ndarray:
        """
        Calculate ensemble confidence scores.
        
        Args:
            X: Feature matrix
            
        Returns:
            Array of confidence scores (0-1)
        """
        meta_features = self.generate_meta_features(X)
        
        # Use ensemble standard deviation as inverse confidence measure
        pred_cols = [col for col in meta_features.columns if col.endswith("_pred")]
        
        if len(pred_cols) > 1:
            std_dev = meta_features[pred_cols].std(axis=1)
            # Convert to confidence (higher std = lower confidence)
            confidence = 1 / (1 + std_dev)
            return confidence.values
        else:
            return np.full(len(X), 0.5)
    
    def evaluate_ensemble(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, float]:
        """
        Evaluate ensemble performance.
        
        Args:
            X: Feature matrix
            y: True labels
            
        Returns:
            Dictionary of performance metrics
        """
        predictions = self.predict(X)
        
        if len(np.unique(y)) == 2:  # Binary classification
            accuracy = accuracy_score(y, predictions.round())
            try:
                proba_predictions = self.predict_proba(X)
                logloss = log_loss(y, proba_predictions)
            except:
                logloss = None
            
            return {
                "accuracy": accuracy,
                "log_loss": logloss,
                "mean_prediction": np.mean(predictions),
                "prediction_std": np.std(predictions)
            }
        else:  # Regression
            mae = mean_absolute_error(y, predictions)
            return {
                "mae": mae,
                "mean_prediction": np.mean(predictions),
                "prediction_std": np.std(predictions)
            }
    
    def get_feature_importance(self) -> Dict[str, float]:
        """Get overall feature importance across ensemble"""
        return self.feature_importance
    
    def add_performance_record(self, metrics: Dict[str, float], timestamp: Optional[datetime] = None):
        """Add performance record for tracking"""
        record = {
            "timestamp": timestamp or datetime.now(),
            "metrics": metrics.copy()
        }
        self.performance_history.append(record)

class AdaptiveEnsemble(EnsemblePredictor):
    """
    Adaptive ensemble that adjusts weights based on recent performance.
    YOLO Mode: Online learning with dynamic model weighting.
    """
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.performance_window = 10  # Look at last 10 predictions
        self.adaptation_rate = 0.1    # How quickly to adapt weights
    
    def update_weights_online(self, prediction: float, actual: float, X_meta: pd.DataFrame):
        """
        Update model weights based on prediction accuracy.
        
        Args:
            prediction: Ensemble prediction
            actual: Actual outcome
            X_meta: Meta-features used for prediction
        """
        error = abs(prediction - actual)
        
        # Update weights based on contribution to error
        for base_model_info in self.base_models:
            name = base_model_info["name"]
            pred_col = f"{name}_pred"
            
            if pred_col in X_meta.columns:
                base_prediction = X_meta[pred_col].iloc[0]
                base_error = abs(base_prediction - actual)
                
                # If base model performed better than ensemble, increase its weight
                if base_error < error:
                    base_model_info["weight"] *= (1 + self.adaptation_rate)
                else:
                    base_model_info["weight"] *= (1 - self.adaptation_rate * 0.5)
                
                # Keep weights in reasonable range
                base_model_info["weight"] = np.clip(base_model_info["weight"], 0.1, 2.0)
        
        # Renormalize weights
        total_weight = sum(model["weight"] for model in self.base_models)
        for model in self.base_models:
            model["weight"] /= total_weight

# Example usage and testing
if __name__ == "__main__":
    print("ðŸŽ¯ Ensemble Methods for Combined Predictions")
    print("YOLO Mode: Advanced ensemble learning pipeline!")
    
    # Create sample ensemble
    ensemble = EnsemblePredictor()
    
    # Add sample base models (mock models for demonstration)
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.linear_model import LogisticRegression
    
    rf_model = RandomForestClassifier(n_estimators=50, random_state=42)
    lr_model = LogisticRegression(random_state=42)
    
    ensemble.add_base_model(rf_model, "random_forest", "classification")
    ensemble.add_base_model(lr_model, "logistic_regression", "classification")
    
    print("âœ… Ensemble initialized with base models")
    
    # Create sample data
    np.random.seed(42)
    n_samples = 1000
    
    X = pd.DataFrame({
        "feature_1": np.random.randn(n_samples),
        "feature_2": np.random.randn(n_samples),
        "feature_3": np.random.randn(n_samples),
        "feature_4": np.random.randn(n_samples)
    })
    
    # Create target with some pattern
    y = ((X["feature_1"] + X["feature_2"] > 0) & (X["feature_3"] < 0.5)).astype(int)
    
    print("âœ… Sample data created")
    
    # Train ensemble
    ensemble.train_ensemble(X, y, ensemble_type="stacking")
    print("âœ… Ensemble trained using stacking method")
    
    # Make predictions
    predictions = ensemble.predict(X)
    probabilities = ensemble.predict_proba(X)
    confidence = ensemble.get_ensemble_confidence(X)
    
    print("âœ… Ensemble predictions generated")
    print(f"   Sample prediction: {predictions[0]:.3f}")
    print(f"   Sample probability: {probabilities[0]:.3f}")
    print(f"   Sample confidence: {confidence[0]:.3f}")
    
    # Evaluate
    metrics = ensemble.evaluate_ensemble(X, y)
    print(f"âœ… Ensemble evaluation: {metrics}")
    
    print("\\nðŸŽ¯ Ensemble Methods Complete:")
    print("âœ… Stacking with meta-learner")
    print("âœ… Blending with weighted averaging")
    print("âœ… Bayesian model averaging")
    print("âœ… Confidence scoring")
    print("âœ… Adaptive weighting")
    print("âœ… Multi-model prediction combination")
    
    print("\\nðŸŽ‰ YOLO Mode Ensemble Learning Ready!")
    print("ðŸ”¥ Advanced prediction combination for superior betting accuracy!")


class GradientBoostingPredictor:
    """
    Production NFL prediction using trained Gradient Boosting Ensemble
    (XGBoost + LightGBM + Sklearn) for spread, total, and moneyline bets.
    """
    
    def __init__(self, model_dir: str = 'models', confidence_threshold: float = 0.55):
        self.model_dir = Path(model_dir)
        self.confidence_threshold = confidence_threshold
        
        try:
            from gradient_boosting_ensemble import GradientBoostingEnsemble
            self.ensemble = GradientBoostingEnsemble(
                spread_model_path=str(self.model_dir / 'spread_ensemble.pkl'),
                total_model_path=str(self.model_dir / 'total_ensemble.pkl'),
                ml_model_path=str(self.model_dir / 'moneyline_ensemble.pkl'),
            )
            self.ensemble.load_models()
            self.ready = True
        except Exception as e:
            logger.warning(f"Could not load gradient boosting models: {e}")
            self.ready = False
    
    def prepare_game_features(self, game_data: Dict) -> pd.DataFrame:
        """Convert game data to feature dataframe (matches training feature order)."""
        required_features = [
            'home_team_pass_yards', 'away_team_pass_yards',
            'home_team_rush_yards', 'away_team_rush_yards',
            'home_team_turnovers', 'away_team_turnovers',
            'spread_line', 'total_line',
            'home_ml_odds', 'away_ml_odds',
            'home_strength', 'away_strength',
            'rest_diff', 'injury_impact_home', 'injury_impact_away',
            'weather_impact', 'is_primetime',
        ]
        
        features = {}
        for feat in required_features:
            features[feat] = [game_data.get(feat, 0.0)]
        
        return pd.DataFrame(features)
    
    def predict_spread(self, game_data: Dict) -> Dict:
        """Predict spread cover with confidence and sizing."""
        if not self.ready:
            return {'error': 'Models not loaded'}
        
        X = self.prepare_game_features(game_data)
        pred, proba = self.ensemble.predict_spread(X)
        pred = pred[0]
        proba = proba[0]
        
        prediction = 'HOME' if pred == 1 else 'AWAY'
        confidence = proba if pred == 1 else (1 - proba)
        
        spread_line = game_data.get('spread_line', 0)
        implied_prob = 0.52
        
        edge = confidence - implied_prob
        kelly_fraction = edge / (confidence - (1 - confidence)) if confidence != 0.5 else 0
        kelly_fraction = max(0, min(kelly_fraction, 0.25))
        
        return {
            'prediction': prediction,
            'probability': float(confidence),
            'confidence': float(confidence),
            'edge': float(edge),
            'kelly_fraction': float(kelly_fraction),
            'unit_size': float(kelly_fraction * 0.5),
            'model': 'spread_ensemble',
        }
    
    def predict_total(self, game_data: Dict) -> Dict:
        """Predict OVER/UNDER with confidence and sizing."""
        if not self.ready:
            return {'error': 'Models not loaded'}
        
        X = self.prepare_game_features(game_data)
        pred, proba = self.ensemble.predict_total(X)
        pred = pred[0]
        proba = proba[0]
        
        prediction = 'OVER' if pred == 1 else 'UNDER'
        confidence = proba if pred == 1 else (1 - proba)
        
        implied_prob = 0.52
        edge = confidence - implied_prob
        kelly_fraction = edge / (confidence - (1 - confidence)) if confidence != 0.5 else 0
        kelly_fraction = max(0, min(kelly_fraction, 0.25))
        
        return {
            'prediction': prediction,
            'probability': float(confidence),
            'confidence': float(confidence),
            'edge': float(edge),
            'kelly_fraction': float(kelly_fraction),
            'unit_size': float(kelly_fraction * 0.5),
            'model': 'total_ensemble',
        }
    
    def predict_moneyline(self, game_data: Dict) -> Dict:
        """Predict moneyline winner with odds implied probability."""
        if not self.ready:
            return {'error': 'Models not loaded'}
        
        X = self.prepare_game_features(game_data)
        pred, proba = self.ensemble.predict_moneyline(X)
        pred = pred[0]
        proba = proba[0]
        
        prediction = 'HOME' if pred == 1 else 'AWAY'
        model_prob = proba if pred == 1 else (1 - proba)
        
        home_odds = game_data.get('home_ml_odds', -110)
        away_odds = game_data.get('away_ml_odds', -110)
        
        home_implied = self._odds_to_prob(home_odds)
        away_implied = self._odds_to_prob(away_odds)
        implied_prob = home_implied if prediction == 'HOME' else away_implied
        
        edge = model_prob - implied_prob
        kelly_fraction = edge / (model_prob - (1 - model_prob)) if model_prob != 0.5 else 0
        kelly_fraction = max(0, min(kelly_fraction, 0.25))
        
        return {
            'prediction': prediction,
            'model_probability': float(model_prob),
            'implied_probability': float(implied_prob),
            'confidence': float(model_prob),
            'edge': float(edge),
            'kelly_fraction': float(kelly_fraction),
            'unit_size': float(kelly_fraction * 0.5),
            'model': 'moneyline_ensemble',
        }
    
    def get_full_prediction(self, game_data: Dict) -> Dict:
        """Get predictions for all three markets."""
        if not self.ready:
            return {'error': 'Models not loaded'}
        
        return {
            'timestamp': pd.Timestamp.now().isoformat(),
            'game': {
                'home_team': game_data.get('home_team', 'UNKNOWN'),
                'away_team': game_data.get('away_team', 'UNKNOWN'),
                'spread_line': game_data.get('spread_line', 0),
                'total_line': game_data.get('total_line', 0),
            },
            'spread': self.predict_spread(game_data),
            'total': self.predict_total(game_data),
            'moneyline': self.predict_moneyline(game_data),
        }
    
    @staticmethod
    def _odds_to_prob(odds: float) -> float:
        """Convert American odds to implied probability"""
        if odds > 0:
            return 100 / (odds + 100)
        else:
            return abs(odds) / (abs(odds) + 100)
