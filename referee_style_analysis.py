"""
Feature engineering and crew classification for the NFL Referee Conspiracy Engine.

Consumes the parquet artifacts generated by `nfl_referee_conspiracy_engine.py`
and produces:
  * A game-level table with officiating crews, penalty metrics, and context.
  * Crew-level aggregates with heuristic labels matching the requested archetypes.
"""

from __future__ import annotations

import asyncio
import io
import json
import logging
import os
import re
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

import aiofiles
import numpy as np
import pandas as pd
import dask.dataframe as dd
from mistletoe import Document
from mistletoe.ast_renderer import ASTRenderer
from pydantic import BaseModel, Field, ValidationError
from sklearn.metrics import accuracy_score

DATA_DIR = Path(os.getenv("REF_CONSPIRACY_DATA_DIR", "data/referee_conspiracy"))
GAME_TABLE_PATH = DATA_DIR / "crew_game_log.parquet"
CREW_FEATURES_PATH = DATA_DIR / "crew_features.parquet"
CREW_LABELS_PATH = DATA_DIR / "crew_labels.parquet"
TEAM_PENALTIES_PATH = DATA_DIR / "team_penalty_log.parquet"
REF_AUTOPSY_PATH = DATA_DIR / "referee_autopsy.json"
NARRATIVE_JSON_PATH = Path(os.getenv("NARRATIVE_JSON_PATH", DATA_DIR / "narrative_notes.json"))
TEAM_ALIAS = {"OAK": "LV", "SD": "LAC", "STL": "LA", "JAC": "JAX"}

logger = logging.getLogger(__name__)


async def async_load_parquet(path: Path, columns: Optional[List[str]] = None) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(f"Expected {path} to exist for parquet load.")
    async with aiofiles.open(path, "rb") as stream:
        raw_bytes = await stream.read()
    buffer = io.BytesIO(raw_bytes)
    return pd.read_parquet(buffer, columns=columns)


def _determine_phase(week: Optional[int], game_type: Optional[str]) -> str:
    """Map an NFL week/game type to early/mid/late."""
    try:
        week_int = int(week) if week is not None else None
    except (TypeError, ValueError):
        week_int = None
    if week_int is None:
        return "late" if (game_type and str(game_type).upper() != "REG") else "mid"
    if week_int <= 6:
        return "early"
    if week_int <= 12:
        return "mid"
    return "late"


def _load_parquet(name: str, force_refresh: bool = False, columns: Optional[List[str]] = None) -> pd.DataFrame:
    path = DATA_DIR / name
    if not path.exists():
        raise FileNotFoundError(
            f"Expected {path} to exist. Run nfl_referee_conspiracy_engine.py first."
        )
    if force_refresh:
        return pd.read_parquet(path, columns=columns)
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = None
    if loop and loop.is_running():
        logger.debug("Event loop running; falling back to synchronous parquet load for %s", path)
        return pd.read_parquet(path, columns=columns)
    return asyncio.run(async_load_parquet(path, columns=columns))


def validate_df(df: pd.DataFrame, columns: List[str], name: str) -> None:
    missing = [col for col in columns if col not in df.columns]
    if missing:
        raise ValueError(f"{name} dataframe missing columns: {missing}")


def _parse_time_column(series: pd.Series) -> pd.Series:
    parsed = pd.to_datetime(series, format="%H:%M", errors="coerce")
    return parsed.dt.hour + parsed.dt.minute / 60.0


def _build_crew_roster(officials: pd.DataFrame) -> pd.DataFrame:
    pivot = (
        officials.pivot_table(
            index=["season", "game_id"],
            columns="off_pos",
            values="name",
            aggfunc="first",
        )
        .reset_index()
        .rename_axis(None, axis=1)
    )
    pivot = pivot.rename(columns={"R": "referee"})
    return pivot


def _aggregate_penalties(penalties: pd.DataFrame) -> pd.DataFrame:
    if penalties.empty:
        return pd.DataFrame(
            columns=[
                "season",
                "game_id",
                "penalties",
                "penalty_yards",
                "flag_density",
                "score_swing_mean_abs",
                "score_swing_positive_rate",
                "total_plays",
                "overtime_plays",
            ]
        )

    penalty_summary = (
        penalties.groupby(["season", "game_id"])
        .agg(
            penalties=("play_id", "count"),
            penalty_yards=("penalty_yards", "sum"),
            score_swing_mean_abs=("score_swing", lambda s: s.fillna(0).abs().mean()),
            score_swing_positive_rate=(
                "score_swing",
                lambda s: np.mean((s.fillna(0)) > 0) if len(s) else np.nan,
            ),
            total_plays=("total_plays", "max"),
            overtime_plays=("overtime_plays", "max"),
        )
        .reset_index()
    )
    penalty_summary["flag_density"] = penalty_summary["penalties"] / penalty_summary[
        "total_plays"
    ].replace(0, np.nan)
    penalty_summary["flag_density"] = penalty_summary["flag_density"].fillna(0.0)
    return penalty_summary


def build_team_penalty_table(force_refresh: bool = False) -> pd.DataFrame:
    """
    Per-team penalty outcomes for each game (calls for/against a specific club).
    """
    if TEAM_PENALTIES_PATH.exists() and not force_refresh:
        return pd.read_parquet(TEAM_PENALTIES_PATH)

    penalties = _load_parquet("penalties_2018_2024.parquet", force_refresh=force_refresh)
    schedules = _load_parquet("schedules_2018_2024.parquet", force_refresh=force_refresh)[
        ["season", "game_id", "home_team", "away_team"]
    ]

    team_summary = (
        penalties.groupby(["season", "game_id", "penalty_team"])
        .agg(
            team_penalties=("play_id", "count"),
            team_penalty_yards=("penalty_yards", "sum"),
            team_score_swing_abs=("score_swing", lambda s: s.fillna(0).abs().sum()),
        )
        .reset_index()
        .rename(columns={"penalty_team": "team"})
    )
    team_summary["team"] = team_summary["team"].replace(TEAM_ALIAS)
    team_summary = team_summary.merge(
        schedules, on=["season", "game_id"], how="left"
    )

    def _role(row: pd.Series) -> str:
        if row["team"] == row["home_team"]:
            return "home"
        if row["team"] == row["away_team"]:
            return "away"
        return "neutral"

    team_summary["role"] = team_summary.apply(_role, axis=1)
    team_summary["home_team"] = team_summary["home_team"].replace(TEAM_ALIAS)
    team_summary["away_team"] = team_summary["away_team"].replace(TEAM_ALIAS)

    team_summary.to_parquet(TEAM_PENALTIES_PATH, index=False)
    return team_summary


def build_game_level_table(force_refresh: bool = False) -> pd.DataFrame:
    """
    Combine officiating rosters, penalties, and schedule context into per-game rows.
    """
    if GAME_TABLE_PATH.exists() and not force_refresh:
        return pd.read_parquet(GAME_TABLE_PATH)

    officials = _load_parquet("officials_2018_2024.parquet", force_refresh=force_refresh)
    penalties = _load_parquet("penalties_2018_2024.parquet", force_refresh=force_refresh)
    schedules = _load_parquet("schedules_2018_2024.parquet", force_refresh=force_refresh)

    crew_roster = _build_crew_roster(officials)
    penalty_summary = _aggregate_penalties(penalties)

    d_crew = dd.from_pandas(crew_roster, npartitions=4)
    d_penalties = dd.from_pandas(penalty_summary, npartitions=4)
    d_sched = dd.from_pandas(
        schedules[
            [
                "game_id",
                "season",
                "game_type",
                "week",
                "weekday",
                "gametime",
                "gameday",
                "away_team",
                "home_team",
                "away_score",
                "home_score",
                "overtime",
                "total",
                "spread_line",
                "total_line",
                "away_spread_odds",
                "home_spread_odds",
                "stadium",
            ]
        ],
        npartitions=4,
    )

    merged = d_crew.merge(d_penalties, on=["season", "game_id"], how="left")
    merged = merged.merge(d_sched, on=["season", "game_id"], how="left")
    game_df = merged.compute().sort_values(["season", "week", "game_id"])

    game_df["penalties"] = game_df["penalties"].fillna(0).astype(int)
    game_df["penalty_yards"] = game_df["penalty_yards"].fillna(0)
    game_df["flag_density"] = game_df["flag_density"].fillna(0.0)
    game_df["score_swing_mean_abs"] = game_df["score_swing_mean_abs"].fillna(0.0)
    game_df["score_swing_positive_rate"] = game_df[
        "score_swing_positive_rate"
    ].fillna(0.0)
    game_df["points_total"] = game_df["home_score"].fillna(0) + game_df[
        "away_score"
    ].fillna(0)
    game_df["margin_abs"] = (game_df["home_score"] - game_df["away_score"]).abs()

    game_df["gametime_hours"] = _parse_time_column(game_df["gametime"])
    game_df["is_primetime"] = game_df.apply(
        lambda row: (
            (row["weekday"] in {"Thursday", "Monday"})
            or (row["weekday"] == "Sunday" and (row["gametime_hours"] or 0) >= 19)
            or (row["weekday"] == "Saturday")
        ),
        axis=1,
    )
    game_df["is_low_visibility"] = game_df.apply(
        lambda row: (
            (row["weekday"] == "Sunday")
            and ((row["gametime_hours"] or 0) < 17)
            and not row["is_primetime"]
        ),
        axis=1,
    )

    overseas_stadium_keywords = [
        "wembley",
        "tottenham",
        "allianz",
        "deutsche",
        "twickenham",
        "estadio",
        "mexico",
        "frankfurt",
    ]
    game_df["is_overseas"] = game_df["stadium"].fillna("").str.lower().apply(
        lambda name: any(keyword in name for keyword in overseas_stadium_keywords)
    )

    game_df.to_parquet(GAME_TABLE_PATH, index=False)
    return game_df


def _primetime_split(group: pd.DataFrame, value_column: str) -> Dict[str, float]:
    prime = group.loc[group["is_primetime"], value_column]
    low_vis = group.loc[group["is_low_visibility"], value_column]
    other = group.loc[~group["is_primetime"], value_column]
    return {
        "primetime_mean": prime.mean() if not prime.empty else np.nan,
        "low_visibility_mean": low_vis.mean() if not low_vis.empty else np.nan,
        "non_primetime_mean": other.mean() if not other.empty else np.nan,
    }


def compute_crew_features(force_refresh: bool = False) -> pd.DataFrame:
    if CREW_FEATURES_PATH.exists() and not force_refresh:
        return pd.read_parquet(CREW_FEATURES_PATH)

    games = build_game_level_table(force_refresh=force_refresh)
    referee_groups = games.groupby("referee")

    metrics = []
    for referee, group in referee_groups:
        summary: Dict[str, float] = {
            "referee": referee,
            "games_worked": len(group),
            "seasons_active": group["season"].nunique(),
            "penalties_per_game": group["penalties"].mean(),
            "penalty_yards_per_game": group["penalty_yards"].mean(),
            "flag_density_mean": group["flag_density"].mean(),
            "points_total_mean": group["points_total"].mean(),
            "margin_mean": group["margin_abs"].mean(),
            "blowout_rate": (group["margin_abs"] >= 17).mean(),
            "close_game_rate": (group["margin_abs"] <= 3).mean(),
            "overtime_rate": (group["overtime"] == 1).mean(),
            "score_swing_mean_abs": group["score_swing_mean_abs"].mean(),
            "score_swing_positive_rate": group["score_swing_positive_rate"].mean(),
            "overseas_games": group["is_overseas"].sum(),
            "overseas_penalties_pg": group.loc[
                group["is_overseas"], "penalties"
            ].mean()
            if group["is_overseas"].any()
            else np.nan,
        }

        penalty_split = _primetime_split(group, "penalties")
        total_split = _primetime_split(group, "points_total")
        swing_split = _primetime_split(group, "score_swing_mean_abs")

        summary.update(
            {
                "penalties_primetime_mean": penalty_split["primetime_mean"],
                "penalties_low_visibility_mean": penalty_split["low_visibility_mean"],
                "penalties_non_prime_mean": penalty_split["non_primetime_mean"],
                "points_primetime_mean": total_split["primetime_mean"],
                "points_low_visibility_mean": total_split["low_visibility_mean"],
                "points_non_prime_mean": total_split["non_primetime_mean"],
                "swing_primetime_mean": swing_split["primetime_mean"],
                "swing_low_visibility_mean": swing_split["low_visibility_mean"],
            }
        )

        metrics.append(summary)

    crew_features = pd.DataFrame(metrics).fillna(0.0)
    crew_features.to_parquet(CREW_FEATURES_PATH, index=False)
    return crew_features


def label_crews(force_refresh: bool = False) -> pd.DataFrame:
    """
    Apply heuristic labels matching the requested archetypes.
    """
    if CREW_LABELS_PATH.exists() and not force_refresh:
        return pd.read_parquet(CREW_LABELS_PATH)

    features = compute_crew_features(force_refresh=force_refresh)
    if features.empty:
        return pd.DataFrame(columns=["referee", "label"])

    penalties_quantiles = features["penalties_per_game"].quantile([0.25, 0.75])
    margin_quantiles = features["margin_mean"].quantile([0.25, 0.75])

    low_penalty_threshold = penalties_quantiles.loc[0.25]
    high_penalty_threshold = penalties_quantiles.loc[0.75]
    low_margin_threshold = margin_quantiles.loc[0.25]
    high_margin_threshold = margin_quantiles.loc[0.75]

    overtime_threshold = 0.15
    if not (features["overtime_rate"] >= overtime_threshold).any():
        overtime_threshold = features["overtime_rate"].quantile(0.9)

    records = []
    for _, row in features.iterrows():
        labels: List[str] = []
        if (
            row["penalties_per_game"] <= low_penalty_threshold
            and row["margin_mean"] >= high_margin_threshold
        ):
            labels.append("low_flags_high_blowouts")

        if (
            row["penalties_per_game"] >= high_penalty_threshold
            and row["margin_mean"] <= low_margin_threshold
        ):
            labels.append("high_penalties_close_games")

        if row["overtime_rate"] >= overtime_threshold:
            labels.append("overtime_frequency_gt_15pct")

        low_vis_points = row["points_low_visibility_mean"]
        non_prime_points = row["points_non_prime_mean"]
        if low_vis_points > 0 and (low_vis_points - non_prime_points) >= 5:
            labels.append("non_tv_scoring_spikes")

        if row["overseas_games"] >= 2 and (
            row["overseas_penalties_pg"] - row["penalties_per_game"]
        ) >= 1:
            labels.append("overseas_flag_surge")

        if not labels:
            labels.append("baseline_control")

        for label in labels:
            records.append({"referee": row["referee"], "label": label})

    labels_df = pd.DataFrame(records)
    labels_df.to_parquet(CREW_LABELS_PATH, index=False)
    return labels_df


def export_referee_timing_index(
    force_refresh: bool = False, output_path: Path = REF_AUTOPSY_PATH
) -> Dict[str, Any]:
    """Export seasonal timing heuristics so deployments can ship a compact JSON."""

    output_path = Path(output_path)
    if output_path.exists() and not force_refresh:
        try:
            return json.loads(output_path.read_text())
        except Exception:  # noqa: broad-except - fall back to regeneration
            pass

    games = build_game_level_table(force_refresh=False)
    if games.empty:
        return {}

    crew_df = games.loc[games["referee"].notna()].copy()
    crew_df["season_phase"] = crew_df.apply(
        lambda row: _determine_phase(row.get("week"), row.get("game_type")), axis=1
    )
    crew_df["overtime"] = crew_df["overtime"].fillna(0).astype(float)

    aggregation = (
        crew_df.groupby(["referee", "season_phase"])
        .agg(
            games=("game_id", "count"),
            penalties_avg=("penalties", "mean"),
            penalty_yards_avg=("penalty_yards", "mean"),
            flag_density_avg=("flag_density", "mean"),
            points_avg=("points_total", "mean"),
            margin_avg=("margin_abs", "mean"),
            overtime_rate=("overtime", "mean"),
            score_swing_avg=("score_swing_mean_abs", "mean"),
        )
        .reset_index()
    )

    labels_lookup: Dict[str, List[str]] = {}
    if CREW_LABELS_PATH.exists():
        try:
            labels_df = pd.read_parquet(CREW_LABELS_PATH)
            for ref, group in labels_df.groupby("referee"):
                labels_lookup[ref] = sorted({str(label) for label in group["label"].dropna()})
        except Exception:  # noqa: broad-except - labels optional
            labels_lookup = {}

    latest_season = int(crew_df["season"].max())
    validation_lookup = (
        crew_df[crew_df["season"] == latest_season]
        .groupby("referee")
        .agg(
            recent_games=("game_id", "count"),
            recent_avg_margin=("margin_abs", "mean"),
            last_seen_week=("week", "max"),
        )
        .to_dict(orient="index")
    )

    def _pattern_summary(row: Any) -> Dict[str, Any]:
        tags: List[str] = []
        adjustment = 0.0
        odds_shift = 0.0

        penalties_avg = float(row.penalties_avg or 0.0)
        overtime_rate = float(row.overtime_rate or 0.0)
        margin_avg = float(row.margin_avg or 0.0)
        points_avg = float(row.points_avg or 0.0)
        score_swing_avg = float(row.score_swing_avg or 0.0)
        phase = str(row.season_phase)

        if penalties_avg >= 7.0:
            tags.append("high_penalties")
            adjustment += 0.08
        elif penalties_avg <= 4.5:
            tags.append("low_penalties")
            odds_shift -= 0.05

        if overtime_rate >= 0.15:
            tags.append("overtime_drama")
            adjustment += 0.12 if phase == "late" else 0.1

        if margin_avg >= 14.0:
            tags.append("blowout_bias")
            adjustment += 0.1 if phase == "mid" else 0.03
        elif margin_avg <= 6.5:
            tags.append("close_game_bias")
            adjustment += 0.05

        if points_avg >= 48.0:
            tags.append("high_scoring_window")
        elif points_avg <= 41.0:
            tags.append("low_scoring_window")

        if score_swing_avg >= 4.5:
            tags.append("swingy_flags")
            adjustment += 0.04

        return {
            "games": int(row.games),
            "penalties_avg": round(penalties_avg, 2),
            "penalty_yards_avg": round(float(row.penalty_yards_avg or 0.0), 2),
            "flag_density_avg": round(float(row.flag_density_avg or 0.0), 3),
            "points_avg": round(points_avg, 2),
            "margin_avg": round(margin_avg, 2),
            "overtime_rate": round(overtime_rate, 3),
            "score_swing_avg": round(score_swing_avg, 2),
            "adjustment": round(adjustment, 3),
            "odds_shift": round(odds_shift, 3),
            "tags": tags,
        }

    index: Dict[str, Any] = {"generated_at": datetime.utcnow().isoformat(), "referees": {}}
    for tuple_row in aggregation.itertuples(index=False):
        summary = _pattern_summary(tuple_row)
        ref = str(tuple_row.referee)
        phase = str(tuple_row.season_phase)
        if ref in labels_lookup:
            summary["labels"] = labels_lookup[ref]
        if ref in validation_lookup:
            summary["validation"] = {
                "season": latest_season,
                "recent_games": int(validation_lookup[ref]["recent_games"]),
                "recent_avg_margin": round(float(validation_lookup[ref]["recent_avg_margin"] or 0.0), 2),
                "last_seen_week": int(validation_lookup[ref]["last_seen_week"] or 0),
            }
        index["referees"].setdefault(ref, {})[phase] = summary

    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(json.dumps(index, indent=2))
    return index


def seasonal_ref_timing(
    base_probability: float,
    base_confidence: float,
    adjustment: float,
    script_weight: float,
    context_factor: float = 1.0,
    rain: float = 0.0,
    blackout: bool = False,
    crowd_noise: float = 0.0,
) -> Dict[str, float]:
    script_weight = float(np.clip(script_weight, 0.0, 0.8))
    base_context = max(0.0, context_factor)
    rain_adj = 0.2 * float(np.clip(rain, 0.0, 1.0))
    blackout_adj = 0.1 if blackout else 0.0
    crowd_adj = 0.15 * float(np.clip(crowd_noise, 0.0, 1.0))
    total_context = base_context + rain_adj + blackout_adj + crowd_adj

    def _sigmoid(x: float) -> float:
        return float(1.0 / (1.0 + np.exp(-x)))

    scaled_weight = script_weight * total_context
    blend_strength = _sigmoid(scaled_weight * 6.0 - 3.0)
    cap = 0.8 if script_weight > 0.3 else 0.5

    raw_probability = base_probability * (1 - blend_strength) + (base_probability + adjustment) * blend_strength
    raw_confidence = base_confidence * (1 - blend_strength) + min(1.0, base_confidence + adjustment * 0.75) * blend_strength

    blended_probability = float(np.clip(raw_probability, 0.0, cap))
    blended_confidence = float(np.clip(raw_confidence, 0.0, cap))

    logger.debug(
        "Seasonal blend | base=%.3f adj=%.3f weight=%.3f base_ctx=%.2f ctx=%.2f rain_adj=%.2f blackout_adj=%.2f crowd_adj=%.2f -> prob=%.3f conf=%.3f",
        base_probability,
        adjustment,
        script_weight,
        base_context,
        total_context,
        rain_adj,
        blackout_adj,
        crowd_adj,
        blended_probability,
        blended_confidence,
    )

    return {
        "probability": blended_probability,
        "confidence": blended_confidence,
        "blend_strength": blend_strength,
        "cap": cap,
        "context_factor": total_context,
    }


def validate_narrative_edge(game_df: pd.DataFrame) -> Optional[float]:
    required = {"narrative_tag", "actual_outcome"}
    if not required.issubset(game_df.columns):
        logger.debug("Narrative validation skipped; columns missing: %s", required - set(game_df.columns))
        return None
    df = game_df.dropna(subset=list(required))
    if df.empty:
        logger.debug("Narrative validation skipped; no data after dropping NaNs.")
        return None
    try:
        y_true = df["actual_outcome"].astype(int)
        y_pred = df["narrative_tag"].astype(int)
        hit_rate = accuracy_score(y_true, y_pred)
        logger.info("Narrative edge validation hit rate: %.3f over %d samples", hit_rate, len(df))
        return float(hit_rate)
    except Exception as exc:
        logger.warning("Failed narrative validation: %s", exc)
        return None


def _flatten_ast_text(node: Any) -> str:
    if isinstance(node, dict):
        if node.get("type") == "raw_text":
            return node.get("content", "")
        if node.get("type") == "text":
            return node.get("content", "")
        if "children" in node:
            return " ".join(_flatten_ast_text(child) for child in node["children"]).strip()
        return ""
    if isinstance(node, list):
        return " ".join(_flatten_ast_text(child) for child in node)
    return str(node)


KEYWORD_WEIGHTS = [
    ("cash cow", 0.8),
    ("dynasty", 0.8),
    ("protected", 0.78),
    ("hero", 0.72),
    ("playoff", 0.7),
    ("rebuild", 0.65),
    ("tank", 0.6),
    ("filler", 0.55),
]


class NarrativeNote(BaseModel):
    script_weight: float = Field(0.0, ge=0.0, le=0.8)
    bet_edge: Optional[str] = None
    details: List[str] = Field(default_factory=list)


async def _load_narrative_notes(
    markdown_path: Path = DATA_DIR / "team_autopsy_notes.md",
    output_path: Path = NARRATIVE_JSON_PATH,
    force_refresh: bool = False,
) -> Dict[str, NarrativeNote]:
    if output_path.exists() and not force_refresh:
        try:
            cached = json.loads(output_path.read_text())
            return {team: NarrativeNote(**payload) for team, payload in cached.items()}
        except (json.JSONDecodeError, ValidationError) as exc:
            logger.warning("Failed to parse cached narrative notes: %s", exc)

    if not markdown_path.exists():
        logger.warning("Narrative markdown not found at %s", markdown_path)
        return {}

    try:
        raw_text = markdown_path.read_text()
    except Exception as exc:  # pragma: no cover - filesystem error
        logger.error("Unable to read narrative markdown: %s", exc)
        return {}

    loop = asyncio.get_event_loop()
    with ASTRenderer() as renderer:
        ast = await loop.run_in_executor(None, renderer.render, Document(raw_text))

    entries: Dict[str, NarrativeNote] = {}
    children = ast.get("children", [])
    idx = 0
    while idx < len(children):
        node = children[idx]
        if node.get("type") == "heading" and node.get("level") == 3:
            team_name = _flatten_ast_text(node).strip()
            idx += 1
            fragments: List[str] = []
            while idx < len(children):
                next_node = children[idx]
                if next_node.get("type") == "heading" and next_node.get("level") <= 3:
                    break
                fragments.append(_flatten_ast_text(next_node).strip())
                idx += 1
            notes = [frag for frag in fragments if frag]
            joined = " ".join(notes).strip()
            lower_joined = joined.lower()

            explicit = re.search(r"script weight[:\s]+([0-9]+)", lower_joined)
            if explicit:
                weight = min(0.8, float(explicit.group(1)) / 100.0)
            else:
                weight = 0.5
                for keyword, val in KEYWORD_WEIGHTS:
                    if keyword in lower_joined:
                        weight = max(weight, val)
                percents = re.findall(r"([0-9]{2,3})\s*%", joined)
                if percents:
                    weight = max(weight, min(0.8, float(percents[0]) / 100.0))

            bet_edge_line = None
            for note in notes:
                if "bet edge" in note.lower():
                    bet_edge_line = note.split(":", 1)[-1].strip()
                    break
                if "â‡’" in note or "=" in note:
                    bet_edge_line = note.strip()
                    break

            try:
                entries[team_name] = NarrativeNote(
                    script_weight=round(weight, 3),
                    bet_edge=bet_edge_line,
                    details=notes,
                )
            except ValidationError as exc:
                logger.warning("Validation failed for %s narrative: %s", team_name, exc)
        else:
            idx += 1

    serialized = {team: note.dict() for team, note in entries.items()}
    try:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(json.dumps(serialized, indent=2, ensure_ascii=False))
    except Exception as exc:  # pragma: no cover - filesystem error
        logger.error("Failed to write narrative JSON: %s", exc)

    return entries


def export_narrative_notes(
    markdown_path: Path = DATA_DIR / "team_autopsy_notes.md",
    output_path: Path = NARRATIVE_JSON_PATH,
) -> Dict[str, Any]:
    notes = asyncio.run(_load_narrative_notes(markdown_path=markdown_path, output_path=output_path, force_refresh=True))
    return {team: note.dict() for team, note in notes.items()}


def live_mode(refresh_callback, poll_seconds: int = 60) -> None:
    while True:
        try:
            refresh_callback()
        except Exception as exc:
            logger.debug("Live mode refresh failed: %s", exc)
        time.sleep(poll_seconds)


def plot_hit_rate(hit_rates: Dict[str, float], output_path: Path = Path("hit_rate_plot.png")) -> None:
    if not hit_rates:
        logger.warning("No hit rates provided; skipping plot.")
        return
    import matplotlib.pyplot as plt
    import seaborn as sns

    teams = list(hit_rates.keys())
    values = [hit_rates[team] for team in teams]
    plt.figure(figsize=(12, 6))
    sns.barplot(x=teams, y=values, palette="rocket")
    plt.xticks(rotation=90)
    plt.ylabel("Hit Rate")
    plt.tight_layout()
    plt.savefig(output_path)
    logger.info("Saved hit rate plot to %s", output_path)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--plot", action="store_true", help="Generate hit rate plot.")
    args = parser.parse_args()

    games = build_game_level_table(force_refresh=False)
    crews = compute_crew_features(force_refresh=False)
    labels = label_crews(force_refresh=False)
    narrative = asyncio.run(_load_narrative_notes(force_refresh=True))
    timing = export_referee_timing_index(force_refresh=False)
    print(
        " | ".join(
            [
                f"Game rows: {len(games)}",
                f"Crews: {len(crews)}",
                f"Labeled records: {len(labels)}",
                f"Timing index referees: {len(timing.get('referees', {}))}",
                f"Narrative entries: {len(narrative)}",
            ]
        )
    )
    if args.plot:
        hit_rate_data = {}
        if {"narrative_tag", "actual_outcome"}.issubset(games.columns):
            hr = validate_narrative_edge(games)
            if hr is not None:
                hit_rate_data = {"league": hr}
        plot_hit_rate(hit_rate_data)


def test_aggregate_penalties_handles_nans():
    penalties = pd.DataFrame(
        {
            "season": [2024, 2024],
            "game_id": ["TEST", "TEST"],
            "play_id": [1, 2],
            "penalty_yards": [10, np.nan],
            "score_swing": [3, np.nan],
            "total_plays": [50, 50],
            "overtime_plays": [0, 0],
        }
    )
    summary = _aggregate_penalties(penalties)
    assert summary.loc[0, "penalties"] == 2
    assert not summary.isna().any().any()
    assert np.isclose(summary.loc[0, "score_swing_mean_abs"], 1.5)


def test_seasonal_ref_timing_blend():
    result = seasonal_ref_timing(
        base_probability=0.5,
        base_confidence=0.4,
        adjustment=0.1,
        script_weight=0.3,
        rain=0.5,
        blackout=True,
        crowd_noise=0.5,
    )
    assert 0.0 <= result["probability"] <= 0.8
    assert 0.0 <= result["confidence"] <= 0.8
