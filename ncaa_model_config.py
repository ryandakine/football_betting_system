#!/usr/bin/env python3
"""
NCAA 12-Model System Configuration - Self-Documenting
=====================================================

PRINCIPLE: Context Embedded (Not External)
Investment ‚Üí System: Don't memorize models, system documents them

WHY 12 MODELS?
- Each model specializes in different aspects
- Ensemble reduces variance
- Catches what individual models miss
- Super intelligence > single model

TESTING CONTEXT:
- 7,331 games (2015-2024)
- User reports: 58-60% win rate (elite level)
- Professional sharp level: 54-58%
- System already validated in production

This config documents:
1. What each model does
2. Why it exists
3. When to use it
4. How it fits in ensemble
"""

from typing import TypedDict, Literal
from enum import Enum


class ModelType(Enum):
    """Types of prediction models"""
    GRADIENT_BOOSTING = "gradient_boosting"
    NEURAL_NETWORK = "neural_network"
    ENSEMBLE = "ensemble"
    BAYESIAN = "bayesian"
    REGRESSION = "regression"


class ModelConfig(TypedDict):
    """Type-safe model configuration"""
    name: str
    type: ModelType
    specialty: str
    why_exists: str
    weight: float
    confidence_calibration: float
    best_for: list[str]
    limitations: str


# ============================================================================
# 12-MODEL SYSTEM CONFIGURATION
# ============================================================================

MODELS: dict[str, ModelConfig] = {
    'xgboost_super': {
        'name': 'XGBoost Super',
        'type': ModelType.GRADIENT_BOOSTING,
        'specialty': 'Overall spread prediction',
        'why_exists': (
            'XGBoost excels at capturing non-linear relationships in sports data. '
            'Handles interaction effects between features (e.g., offense strength √ó opponent defense). '
            'Most reliable baseline model.'
        ),
        'weight': 1.2,  # Highest weight - most reliable
        'confidence_calibration': 0.95,
        'best_for': [
            'Standard conference matchups',
            'Data-rich situations (long team history)',
            'Non-extreme situations'
        ],
        'limitations': (
            'Can overfit on small datasets. '
            'Less effective for unprecedented situations (e.g., backup QB starting first game).'
        )
    },

    'neural_net_deep': {
        'name': 'Deep Neural Network',
        'type': ModelType.NEURAL_NETWORK,
        'specialty': 'Complex pattern recognition',
        'why_exists': (
            'Deep learning captures subtle patterns XGBoost misses. '
            'Excels at temporal patterns (momentum, trends). '
            'Learns feature representations automatically.'
        ),
        'weight': 1.1,
        'confidence_calibration': 0.90,
        'best_for': [
            'Teams with momentum (win/loss streaks)',
            'Complex multi-factor situations',
            'Late-season predictions (more training data)'
        ],
        'limitations': (
            'Requires more training data. '
            'Can be overconfident. '
            'Black box (hard to interpret).'
        )
    },

    'alt_spread': {
        'name': 'Alternative Spread Model',
        'type': ModelType.GRADIENT_BOOSTING,
        'specialty': 'Market inefficiency detection',
        'why_exists': (
            'Trained specifically to find where market spreads are wrong. '
            'Compares historical spreads to actual results. '
            'Identifies systematic market biases.'
        ),
        'weight': 1.15,
        'confidence_calibration': 0.92,
        'best_for': [
            'High-profile teams (where market has bias)',
            'Conference games (market undervalues familiarity)',
            'Tuesday/Wednesday games (softer lines)'
        ],
        'limitations': (
            'Needs market spread data to function. '
            'Less useful for neutral site games.'
        )
    },

    'bayesian_ensemble': {
        'name': 'Bayesian Ensemble',
        'type': ModelType.BAYESIAN,
        'specialty': 'Uncertainty quantification',
        'why_exists': (
            'Provides probabilistic predictions with confidence intervals. '
            'Better at saying "I don\'t know" than point predictors. '
            'Combines prior knowledge with data.'
        ),
        'weight': 0.9,
        'confidence_calibration': 1.0,  # Already well-calibrated
        'best_for': [
            'Low-data situations (new teams, limited history)',
            'Uncertainty estimation',
            'Risk assessment'
        ],
        'limitations': (
            'Computationally expensive. '
            'Conservative (wide confidence intervals).'
        )
    },

    'momentum_model': {
        'name': 'Momentum & Trends',
        'type': ModelType.REGRESSION,
        'specialty': 'Recent performance weighting',
        'why_exists': (
            'Last 3 games more predictive than season average. '
            'Captures hot/cold streaks, injuries, coaching changes. '
            'Market often slow to adjust to recent trends.'
        ),
        'weight': 1.0,
        'confidence_calibration': 0.88,
        'best_for': [
            'Teams on streaks (5+ game win/loss)',
            'Mid-season predictions (after 5+ games played)',
            'Identifying form changes'
        ],
        'limitations': (
            'Overreacts to small samples. '
            'Can\'t use early in season (insufficient data).'
        )
    },

    'situational': {
        'name': 'Situational Model',
        'type': ModelType.GRADIENT_BOOSTING,
        'specialty': 'Context-aware predictions',
        'why_exists': (
            'Road vs home matters (3.5 pt advantage). '
            'Rivalry games different than normal games. '
            'Weather, rest days, travel distance all matter.'
        ),
        'weight': 1.05,
        'confidence_calibration': 0.93,
        'best_for': [
            'Road underdogs (market undervalues home advantage)',
            'Short rest situations',
            'Weather games (wind, rain)'
        ],
        'limitations': (
            'Requires situational features (not always available). '
            'Less useful for neutral site games.'
        )
    },

    'advanced_stats': {
        'name': 'Advanced Analytics',
        'type': ModelType.REGRESSION,
        'specialty': 'Efficiency metrics (EPA, Success Rate)',
        'why_exists': (
            'Points per game is noisy. EPA (Expected Points Added) more predictive. '
            'Success rate captures consistency. '
            'Market often uses basic stats only.'
        ),
        'weight': 1.1,
        'confidence_calibration': 0.91,
        'best_for': [
            'Matchups with efficiency mismatches',
            'Identifying overrated/underrated teams',
            'Late-season (stabilized metrics)'
        ],
        'limitations': (
            'Advanced stats require API access. '
            'Early season stats unreliable (small sample).'
        )
    },

    'drive_outcomes': {
        'name': 'Drive Outcomes Model',
        'type': ModelType.NEURAL_NETWORK,
        'specialty': 'Scoring efficiency vs position',
        'why_exists': (
            'Not all yards equal. Red zone efficiency critical. '
            'Turnovers in own territory change games. '
            'Market doesn\'t fully price this in spreads.'
        ),
        'weight': 0.95,
        'confidence_calibration': 0.89,
        'best_for': [
            'Red zone efficiency disparities',
            'Turnover-prone teams',
            'Field position battles'
        ],
        'limitations': (
            'Requires play-by-play data. '
            'Complex feature engineering.'
        )
    },

    'opponent_adjusted': {
        'name': 'Opponent-Adjusted Efficiency',
        'type': ModelType.REGRESSION,
        'specialty': 'Strength of schedule weighting',
        'why_exists': (
            '400 yards vs top defense ‚â† 400 yards vs weak defense. '
            'Adjusts all stats for opponent quality. '
            'Reveals true team strength.'
        ),
        'weight': 1.08,
        'confidence_calibration': 0.94,
        'best_for': [
            'Undefeated teams (are they good or lucky?)',
            'Conference crossover games',
            'Identifying schedule flukes'
        ],
        'limitations': (
            'Requires full season of data for opponent adjustments. '
            'Early season not reliable.'
        )
    },

    'special_teams': {
        'name': 'Special Teams Impact',
        'type': ModelType.REGRESSION,
        'specialty': 'FG%, punt returns, kickoffs',
        'why_exists': (
            'Special teams worth ~3 points per game on average. '
            'Market often ignores this completely. '
            'Free edge in close games.'
        ),
        'weight': 0.85,
        'confidence_calibration': 0.87,
        'best_for': [
            'Close spreads (within 3 points)',
            'Bad weather games (kicking matters more)',
            'Teams with elite kickers'
        ],
        'limitations': (
            'Small effect size. '
            'Only matters in close games.'
        )
    },

    'pace_tempo': {
        'name': 'Pace & Tempo Model',
        'type': ModelType.REGRESSION,
        'specialty': 'Possessions per game, total points',
        'why_exists': (
            'Fast pace = more possessions = higher variance. '
            'Slow pace = fewer possessions = favors better team. '
            'Market sometimes mixes up pace with scoring.'
        ),
        'weight': 0.90,
        'confidence_calibration': 0.86,
        'best_for': [
            'Pace mismatches (fast vs slow)',
            'Totals betting (over/under)',
            'Blowout potential assessment'
        ],
        'limitations': (
            'Secondary factor. '
            'Less important than raw efficiency.'
        )
    },

    'game_script': {
        'name': 'Game Script Predictor',
        'type': ModelType.NEURAL_NETWORK,
        'specialty': 'How game will unfold (score by quarter)',
        'why_exists': (
            'Garbage time matters for spreads. '
            'Early leads change play-calling. '
            'Predicting game flow helps with live betting.'
        ),
        'weight': 0.95,
        'confidence_calibration': 0.88,
        'best_for': [
            'Large spreads (likely blowouts)',
            'Live betting adjustments',
            'Understanding variance'
        ],
        'limitations': (
            'Speculative. '
            'More useful for in-game than pre-game.'
        )
    },
}


# ============================================================================
# ENSEMBLE CONFIGURATION
# ============================================================================

ENSEMBLE_CONFIG = {
    'aggregation_method': 'weighted_average',
    'min_models_required': 8,  # Need 8/12 to make prediction
    'outlier_detection': True,  # Remove predictions >2œÉ from mean
    'confidence_calibration': 0.90,  # Global calibration multiplier
    'fractional_kelly': 0.25,  # Bet 25% of full Kelly

    'WHY_WEIGHTED_AVERAGE': (
        'Simple average treats all models equally (wrong). '
        'Weighted average gives more influence to reliable models. '
        'Weights learned from historical backtest performance.'
    ),

    'WHY_8_OF_12_REQUIRED': (
        'If only 5-6 models agree, prediction unreliable. '
        'Requiring 8/12 ensures consensus. '
        'Better to skip bet than force prediction.'
    ),

    'WHY_OUTLIER_DETECTION': (
        'If one model predicts Alabama -35 and others say -14, ignore it. '
        'Prevents single broken model from skewing ensemble. '
        'Uses 2œÉ threshold (keeps 95% of predictions).'
    ),

    'WHY_0_90_CALIBRATION': (
        'Models tend to be overconfident. '
        '90% confidence really means ~81% (0.90¬≤). '
        'Conservative calibration prevents over-betting.'
    ),

    'WHY_FRACTIONAL_KELLY': (
        'Full Kelly has 100% bankruptcy risk over time. '
        '25% Kelly = safe bet sizing with 98%+ survival rate. '
        'Sacrifices some growth for safety.'
    ),
}


# ============================================================================
# VALIDATION & DISCOVERY FUNCTIONS
# ============================================================================

def get_model_config(model_name: str) -> ModelConfig:
    """
    Runtime discovery: Agent queries system for model capabilities

    WHY: Agent doesn't memorize models, discovers at runtime
    """
    if model_name not in MODELS:
        available = ', '.join(MODELS.keys())
        raise ValueError(
            f"Unknown model: '{model_name}'\n"
            f"Available models: {available}"
        )

    return MODELS[model_name]


def list_models() -> list[str]:
    """List all configured models"""
    return list(MODELS.keys())


def get_models_by_specialty(specialty: str) -> list[str]:
    """Find models specialized for specific situations"""
    return [
        name for name, config in MODELS.items()
        if specialty.lower() in config['specialty'].lower()
    ]


def calculate_ensemble_weights() -> dict[str, float]:
    """
    Get normalized ensemble weights

    WHY: Agent discovers weights at runtime, can't hardcode wrong values
    """
    total_weight = sum(config['weight'] for config in MODELS.values())

    normalized = {
        name: config['weight'] / total_weight
        for name, config in MODELS.items()
    }

    return normalized


def validate_model_config():
    """
    Runtime validation: Ensure all models properly configured

    WHY: Fail fast if config incomplete
    """
    required_fields = ['name', 'type', 'specialty', 'why_exists', 'weight']

    errors = []
    for model_name, config in MODELS.items():
        for field in required_fields:
            if field not in config or not config[field]:
                errors.append(f"Model '{model_name}' missing field: {field}")

    if errors:
        raise ValueError(
            "Model configuration errors:\n" + "\n".join(errors)
        )

    print("‚úÖ All 12 models properly configured")


# ============================================================================
# SELF-DOCUMENTING DISPLAY
# ============================================================================

if __name__ == "__main__":
    """
    Display model configuration

    Usage: python ncaa_model_config.py
    """

    print("\n" + "="*80)
    print("üß† NCAA 12-MODEL SUPER INTELLIGENCE SYSTEM")
    print("="*80 + "\n")

    print("SYSTEM OVERVIEW:")
    print(f"  Total models: {len(MODELS)}")
    print(f"  Ensemble method: {ENSEMBLE_CONFIG['aggregation_method']}")
    print(f"  Min models required: {ENSEMBLE_CONFIG['min_models_required']}/12")
    print(f"  Confidence calibration: {ENSEMBLE_CONFIG['confidence_calibration']}x")
    print(f"  Fractional Kelly: {ENSEMBLE_CONFIG['fractional_kelly']}x")
    print()

    print("\n" + "="*80)
    print("üìä MODEL BREAKDOWN")
    print("="*80 + "\n")

    # Group by type
    by_type = {}
    for name, config in MODELS.items():
        model_type = config['type'].value
        if model_type not in by_type:
            by_type[model_type] = []
        by_type[model_type].append((name, config))

    for model_type, models in by_type.items():
        print(f"\nüîß {model_type.upper().replace('_', ' ')}")
        print("-" * 80)

        for name, config in models:
            print(f"\n  {config['name']} ({name})")
            print(f"  Specialty: {config['specialty']}")
            print(f"  Weight: {config['weight']:.2f}")
            print(f"  Why: {config['why_exists'][:100]}...")
            print(f"  Best for: {', '.join(config['best_for'][:2])}")

    print("\n" + "="*80)
    print("‚öñÔ∏è  NORMALIZED ENSEMBLE WEIGHTS")
    print("="*80 + "\n")

    weights = calculate_ensemble_weights()
    sorted_weights = sorted(weights.items(), key=lambda x: x[1], reverse=True)

    for name, weight in sorted_weights:
        bar = "‚ñà" * int(weight * 100)
        print(f"  {name:25} {weight:6.2%} {bar}")

    print("\n" + "="*80)
    print("üéØ ENSEMBLE CONFIGURATION")
    print("="*80 + "\n")

    for key, value in ENSEMBLE_CONFIG.items():
        if key.startswith('WHY_'):
            continue
        print(f"  {key}: {value}")

    print("\n" + "="*80)
    print("‚úÖ VALIDATION")
    print("="*80 + "\n")

    validate_model_config()
    print(f"  System ready for predictions")
    print()
