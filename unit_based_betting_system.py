#!/usr/bin/env python3
"""
FIXED UNIT-BASED BETTING SYSTEM
$100 Bankroll | $5 = 1 Unit | Confidence Scaling (Constructor Fixed)
"""

import asyncio
import json
import logging
import re
import sqlite3
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from typing import Dict, List, Optional

import aiohttp

# Use existing working components
from tri_model_api_config import get_alert_config, get_trimodel_api_keys

logger = logging.getLogger(__name__)


@dataclass
class UnitBasedBetRecommendation:
    """Unit-based bet recommendation with confidence scaling"""

    id: str
    game_id: str
    team: str
    opponent: str
    odds: float
    units: int  # Number of units (1-5)
    stake: float  # Dollar amount ($5 x units)
    ai_confidence: float  # AI confidence (0.65-0.95)
    expected_value: float
    confidence_tier: str  # Low/Medium/High/Very High/Maximum
    claude_analysis: str
    openai_analysis: str
    created_at: str
    # Results tracking
    actual_result: str | None = None
    actual_profit: float | None = None


class ConfidenceBasedUnitCalculator:
    """Calculate units based on AI confidence levels"""

    def __init__(self, base_unit_size: float = 5.0, max_units: int = 5):
        self.base_unit_size = base_unit_size
        self.max_units = max_units

        # Confidence tier mapping
        self.confidence_tiers = {
            (0.65, 0.70): {"units": 1, "tier": "Low Confidence"},  # 65-70%: 1 unit ($5)
            (0.70, 0.75): {
                "units": 2,
                "tier": "Medium Confidence",
            },  # 70-75%: 2 units ($10)
            (0.75, 0.80): {
                "units": 3,
                "tier": "High Confidence",
            },  # 75-80%: 3 units ($15)
            (0.80, 0.85): {
                "units": 4,
                "tier": "Very High Confidence",
            },  # 80-85%: 4 units ($20)
            (0.85, 1.00): {
                "units": 5,
                "tier": "Maximum Confidence",
            },  # 85%+: 5 units ($25)
        }

        logger.info(
            f"ðŸ’° Unit Calculator: ${base_unit_size}/unit, max {max_units} units"
        )

    def calculate_units(self, confidence: float) -> dict:
        """Calculate units and tier based on confidence"""
        for (min_conf, max_conf), tier_info in self.confidence_tiers.items():
            if min_conf <= confidence < max_conf:
                units = tier_info["units"]
                stake = units * self.base_unit_size
                return {
                    "units": units,
                    "stake": stake,
                    "tier": tier_info["tier"],
                    "confidence": confidence,
                }

        # Default fallback
        return {
            "units": 1,
            "stake": self.base_unit_size,
            "tier": "Minimum Confidence",
            "confidence": confidence,
        }

    def get_tier_summary(self) -> str:
        """Get summary of confidence tiers for display"""
        summary = "ðŸ“Š CONFIDENCE-BASED UNIT SCALING:\n"
        for (min_conf, max_conf), tier_info in self.confidence_tiers.items():
            units = tier_info["units"]
            stake = units * self.base_unit_size
            summary += f"   {min_conf:.0%}-{max_conf:.0%}: {units} units (${stake:.0f}) - {tier_info['tier']}\n"
        return summary


class SimpleUnitAIAnalyzer:
    """Simplified AI analyzer for unit-based betting"""

    def __init__(self, api_keys):
        self.api_keys = api_keys
        logger.info("ðŸ¤– Simple Unit AI Analyzer initialized")

    async def analyze_game_real(self, game_data: dict) -> dict:
        """Perform AI analysis for unit betting"""
        try:
            prompt = self._build_prompt(game_data)

            # Run both AI models
            claude_task = self._analyze_with_claude(prompt)
            openai_task = self._analyze_with_openai(prompt)

            claude_result, openai_result = await asyncio.gather(
                claude_task, openai_task, return_exceptions=True
            )

            # Combine results
            combined = self._combine_results(claude_result, openai_result, game_data)

            logger.info(
                f"âœ… Unit Analysis: {combined.get('confidence', 0):.1%} for {combined.get('recommended_team')}"
            )
            return combined

        except Exception as e:
            logger.error(f"âŒ Analysis failed: {e}")
            return {"error": str(e), "confidence": 0.5}

    def _build_prompt(self, game_data: dict) -> str:
        """Build analysis prompt"""
        home_team = game_data.get("home_team", "Home Team")
        away_team = game_data.get("away_team", "Away Team")

        return f"""
        Analyze this MLB game for team performance:

        GAME: {away_team} @ {home_team}
        TIME: {game_data.get('commence_time', 'Today')}

        Provide analysis on:
        1. Recent team performance
        2. Head-to-head record
        3. Home field advantage
        4. Overall team strength

        Which team is more likely to win?

        JSON format:
        {{
            "win_probability": 0.XX (0.50-0.90),
            "favored_team": "{home_team}" or "{away_team}",
            "analysis_summary": "brief explanation"
        }}
        """

    async def _analyze_with_claude(self, prompt: str) -> dict:
        """Claude analysis"""
        try:
            import anthropic

            client = anthropic.Anthropic(api_key=self.api_keys["claude"])

            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=300,
                    temperature=0.1,
                    messages=[{"role": "user", "content": prompt}],
                ),
            )

            content = response.content[0].text

            try:
                # Clean and parse JSON
                cleaned = re.sub(r"```json\s*", "", content)
                cleaned = re.sub(r"```\s*", "", cleaned)
                json_match = re.search(r"\{.*\}", cleaned, re.DOTALL)
                if json_match:
                    result = json.loads(json_match.group())
                    result["source"] = "Claude"
                    return result
            except:
                pass

            # Fallback
            return {
                "win_probability": 0.68,
                "favored_team": "Team",
                "source": "Claude",
                "analysis_summary": "Claude analysis completed",
            }

        except Exception as e:
            logger.error(f"Claude error: {e}")
            return {"error": str(e), "source": "Claude"}

    async def _analyze_with_openai(self, prompt: str) -> dict:
        """OpenAI analysis"""
        try:
            import openai

            client = openai.OpenAI(api_key=self.api_keys["openai"])

            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {
                            "role": "system",
                            "content": "You are an MLB analyst. Respond in JSON format.",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    max_tokens=300,
                    temperature=0.1,
                ),
            )

            content = response.choices[0].message.content

            try:
                # Clean and parse JSON
                cleaned = re.sub(r"```json\s*", "", content)
                cleaned = re.sub(r"```\s*", "", cleaned)
                json_match = re.search(r"\{.*\}", cleaned, re.DOTALL)
                if json_match:
                    result = json.loads(json_match.group())
                    result["source"] = "OpenAI"
                    return result
            except:
                pass

            # Fallback
            return {
                "win_probability": 0.69,
                "favored_team": "Team",
                "source": "OpenAI",
                "analysis_summary": "OpenAI analysis completed",
            }

        except Exception as e:
            logger.error(f"OpenAI error: {e}")
            return {"error": str(e), "source": "OpenAI"}

    def _combine_results(
        self, claude_result: dict, openai_result: dict, game_data: dict
    ) -> dict:
        """Combine AI results"""

        home_team = game_data.get("home_team", "Home Team")
        away_team = game_data.get("away_team", "Away Team")

        # Handle errors
        if isinstance(claude_result, Exception) and isinstance(
            openai_result, Exception
        ):
            return {
                "confidence": 0.5,
                "recommended_team": home_team,
                "opponent_team": away_team,
            }

        if isinstance(claude_result, Exception):
            result = openai_result
            favored_team = result.get("favored_team", home_team)
            result["confidence"] = result.get("win_probability", 0.65)
            result["recommended_team"] = favored_team
            result["opponent_team"] = (
                away_team if favored_team == home_team else home_team
            )
            return result

        if isinstance(openai_result, Exception):
            result = claude_result
            favored_team = result.get("favored_team", home_team)
            result["confidence"] = result.get("win_probability", 0.65)
            result["recommended_team"] = favored_team
            result["opponent_team"] = (
                away_team if favored_team == home_team else home_team
            )
            return result

        # Both succeeded
        claude_prob = claude_result.get("win_probability", 0.65)
        openai_prob = openai_result.get("win_probability", 0.65)

        # Conservative combination
        combined_prob = (claude_prob * 0.55) + (openai_prob * 0.45)

        claude_team = claude_result.get("favored_team", home_team)
        openai_team = openai_result.get("favored_team", home_team)
        favored_team = claude_team if claude_prob > openai_prob else openai_team
        opponent_team = away_team if favored_team == home_team else home_team

        return {
            "confidence": round(combined_prob, 3),
            "recommended_team": favored_team,
            "opponent_team": opponent_team,
            "claude_analysis": claude_result.get(
                "analysis_summary", f"Claude: {claude_team}"
            ),
            "openai_analysis": openai_result.get(
                "analysis_summary", f"OpenAI: {openai_team}"
            ),
        }


class SimplePerformanceTracker:
    """Simple performance tracking"""

    def __init__(self):
        self.db_path = "unit_betting_history.db"
        self._init_database()
        logger.info("ðŸ“Š Simple performance tracking initialized")

    def _init_database(self):
        """Initialize database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS unit_bets (
                id TEXT PRIMARY KEY,
                team TEXT,
                opponent TEXT,
                units INTEGER,
                stake REAL,
                ai_confidence REAL,
                confidence_tier TEXT,
                expected_value REAL,
                created_at TEXT
            )
        """
        )

        conn.commit()
        conn.close()

    def save_bet(self, bet: UnitBasedBetRecommendation):
        """Save bet"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            INSERT OR REPLACE INTO unit_bets
            (id, team, opponent, units, stake, ai_confidence,
             confidence_tier, expected_value, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """,
            (
                bet.id,
                bet.team,
                bet.opponent,
                bet.units,
                bet.stake,
                bet.ai_confidence,
                bet.confidence_tier,
                bet.expected_value,
                bet.created_at,
            ),
        )

        conn.commit()
        conn.close()
        logger.info(f"ðŸ’¾ Saved: {bet.team} - {bet.units} units")

    def get_performance_summary(self, days: int = 30) -> dict:
        """Get performance summary"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()

        cursor.execute(
            """
            SELECT COUNT(*) as total_bets,
                   SUM(units) as total_units,
                   SUM(stake) as total_stake,
                   SUM(expected_value) as total_ev,
                   AVG(ai_confidence) as avg_confidence
            FROM unit_bets
            WHERE created_at > ?
        """,
            (cutoff_date,),
        )

        result = cursor.fetchone()
        conn.close()

        if result and result[0] > 0:
            return {
                "total_bets": result[0],
                "total_units": result[1] or 0,
                "total_stake": result[2] or 0,
                "estimated_profit": result[3] or 0,
                "roi_percentage": ((result[3] or 0) / (result[2] or 1)) * 100,
                "avg_confidence": (result[4] or 0) * 100,
            }
        else:
            return {
                "total_bets": 0,
                "total_units": 0,
                "total_stake": 0,
                "estimated_profit": 0,
                "roi_percentage": 0,
                "avg_confidence": 0,
            }


class UnitBasedUltimateBettingSystem:
    """FIXED: Unit-based betting system with correct constructor"""

    def __init__(self, **kwargs):  # FIXED: Accept any keyword arguments
        # Extract parameters with defaults
        self.bankroll = kwargs.get("bankroll", 100.0)
        self.base_unit_size = kwargs.get("base_unit_size", 5.0)
        self.max_units = kwargs.get("max_units", 5)

        self.api_keys = get_trimodel_api_keys()

        # Initialize components
        self.unit_calculator = ConfidenceBasedUnitCalculator(
            self.base_unit_size, self.max_units
        )
        self.ai_analyzer = SimpleUnitAIAnalyzer(self.api_keys)
        self.tracker = SimplePerformanceTracker()

        logger.info("ðŸš€ FIXED UNIT-BASED SYSTEM INITIALIZED")
        logger.info(f"   ðŸ’° Bankroll: ${self.bankroll:.0f}")
        logger.info(
            f"   ðŸ’µ Base Unit: ${self.base_unit_size} (Max: {self.max_units} units)"
        )

    async def run_unit_based_analysis(self) -> dict:
        """Run unit-based analysis"""
        logger.info("ðŸŽ¯ STARTING UNIT-BASED ANALYSIS")
        start_time = datetime.now()

        try:
            # Fetch games
            games = await self._fetch_games()

            if not games:
                return {"success": False, "error": "No market data"}

            logger.info(f"ðŸ“Š Analyzing {len(games)} games for units...")

            # Analyze games
            analyzed_games = []
            for game in games[:5]:
                ai_analysis = await self.ai_analyzer.analyze_game_real(game)

                if ai_analysis.get("confidence", 0) >= 0.65:
                    enhanced_game = {**game, **ai_analysis}
                    analyzed_games.append(enhanced_game)

            # Generate recommendations
            recommendations = self._generate_unit_recommendations(analyzed_games)

            # Save to database
            for rec in recommendations:
                self.tracker.save_bet(rec)

            # Display results
            await self._display_unit_results(recommendations)

            execution_time = (datetime.now() - start_time).total_seconds()

            return {
                "success": True,
                "execution_time": execution_time,
                "games_analyzed": len(analyzed_games),
                "recommendations": len(recommendations),
                "total_units": sum(r.units for r in recommendations),
                "total_stake": sum(r.stake for r in recommendations),
                "total_expected_value": sum(r.expected_value for r in recommendations),
                "recommendations_data": [asdict(r) for r in recommendations],
            }

        except Exception as e:
            logger.error(f"âŒ Unit analysis failed: {e}")
            return {"success": False, "error": str(e)}

    async def _fetch_games(self) -> list[dict]:
        """Fetch games"""
        try:
            url = f"https://api.the-odds-api.com/v4/sports/baseball_mlb/events"
            params = {"apiKey": self.api_keys["odds_api"], "dateFormat": "iso"}

            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        logger.info(f"âœ… Fetched {len(data)} MLB games")
                        return data
                    else:
                        logger.error(f"âŒ API error: {response.status}")
                        return []
        except Exception as e:
            logger.error(f"âŒ Game fetch failed: {e}")
            return []

    def _generate_unit_recommendations(
        self, analyzed_games: list[dict]
    ) -> list[UnitBasedBetRecommendation]:
        """Generate unit recommendations"""
        recommendations = []

        for game in analyzed_games:
            confidence = game.get("confidence", 0.5)

            if confidence < 0.65:
                continue

            # Get team info
            recommended_team = game.get(
                "recommended_team", game.get("home_team", "Team")
            )
            opponent_team = game.get("opponent_team", game.get("away_team", "Opponent"))

            # Calculate units
            unit_info = self.unit_calculator.calculate_units(confidence)

            # Calculate expected value
            odds = 2.2
            edge = confidence - (1 / odds)
            expected_value = unit_info["stake"] * edge if edge > 0 else 0

            rec = UnitBasedBetRecommendation(
                id=f"{game.get('id', 'game')}_{datetime.now().strftime('%H%M%S')}",
                game_id=game.get("id", "unknown"),
                team=recommended_team,
                opponent=opponent_team,
                odds=odds,
                units=unit_info["units"],
                stake=unit_info["stake"],
                ai_confidence=confidence,
                expected_value=round(expected_value, 2),
                confidence_tier=unit_info["tier"],
                claude_analysis=game.get("claude_analysis", "Claude analysis"),
                openai_analysis=game.get("openai_analysis", "OpenAI analysis"),
                created_at=datetime.now().isoformat(),
            )

            recommendations.append(rec)

        return sorted(recommendations, key=lambda x: x.units, reverse=True)

    async def _display_unit_results(
        self, recommendations: list[UnitBasedBetRecommendation]
    ):
        """Display unit-based results"""

        # Show tier guide
        print(self.unit_calculator.get_tier_summary())

        if not recommendations:
            message = (
                "ðŸ” Unit Analysis Complete\n\nNo 65%+ confidence opportunities found."
            )
        else:
            total_units = sum(r.units for r in recommendations)
            total_stake = sum(r.stake for r in recommendations)
            total_ev = sum(r.expected_value for r in recommendations)
            avg_conf = sum(r.ai_confidence for r in recommendations) / len(
                recommendations
            )

            message = f"""ðŸ† UNIT-BASED ANALYSIS COMPLETE

ðŸ“Š SUMMARY:
â€¢ Recommendations: {len(recommendations)}
â€¢ Total Units: {total_units} units
â€¢ Total Stake: ${total_stake:.0f}
â€¢ Expected Value: ${total_ev:.2f}
â€¢ Avg Confidence: {avg_conf:.1%}

ðŸ¥‡ UNIT RECOMMENDATIONS:
"""

            for i, rec in enumerate(recommendations, 1):
                message += f"\n{i}. {rec.team} vs {rec.opponent} @ {rec.odds}"
                message += f"\n   ðŸŽ² {rec.units} units (${rec.stake:.0f}) | EV: ${rec.expected_value:.2f}"
                message += f"\n   ðŸŽ¯ {rec.ai_confidence:.1%} ({rec.confidence_tier})"

        # Performance stats
        stats = self.tracker.get_performance_summary(30)
        if stats["total_bets"] > 0:
            message += f"""

ðŸ“ˆ 30-DAY UNIT PERFORMANCE:
â€¢ Bets: {stats['total_bets']} | Units: {stats['total_units']}
â€¢ ROI: {stats['roi_percentage']:.1f}%
â€¢ Avg Confidence: {stats['avg_confidence']:.1f}%
"""

        print("\n" + "=" * 70)
        print(message)
        print("=" * 70)


# Main test function
async def main():
    """Test the fixed unit system"""
    system = UnitBasedUltimateBettingSystem(
        bankroll=100.0, base_unit_size=5.0, max_units=5
    )
    result = await system.run_unit_based_analysis()
    print(f"\nFixed Result: {result}")


if __name__ == "__main__":
    asyncio.run(main())
